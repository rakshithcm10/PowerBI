{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape unique multi brand in snapdeal Mrp, offer Price,company Product name \n",
    "#pereform data analytic using PowerBi to ellustarte prodct vs company wrt avg price also create DAX measure to calculate % of discount on the product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoup4\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "     ---------------------------------------- 0.0/143.0 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/143.0 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/143.0 kB 435.7 kB/s eta 0:00:01\n",
      "     --------------- --------------------- 61.4/143.0 kB 544.7 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 133.1/143.0 kB 983.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 143.0/143.0 kB 850.9 kB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2 (from BeautifulSoup4)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, BeautifulSoup4\n",
      "Successfully installed BeautifulSoup4-4.12.2 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fake-useragent\n",
      "  Obtaining dependency information for fake-useragent from https://files.pythonhosted.org/packages/56/56/f72e9ca4f9cfb966f489c2b8ea04c67fa8d0cfbb62b1651cb9d6aef110a6/fake_useragent-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading fake_useragent-1.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\msis\\anaconda3\\envs\\quickstart\\lib\\site-packages (from fake-useragent) (6.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\msis\\anaconda3\\envs\\quickstart\\lib\\site-packages (from importlib-resources>=5.0->fake-useragent) (3.11.0)\n",
      "Downloading fake_useragent-1.3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: fake-useragent\n",
      "Successfully installed fake-useragent-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fake-useragent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Data has been saved to 'LabbPhone.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from fake_useragent import UserAgent  \n",
    " \n",
    "\n",
    "Phones = []\n",
    "\n",
    "def scrape_page(url):\n",
    "    user_agent = UserAgent()  # Create a UserAgent object to generate random user-agents\n",
    "    headers = {'User-Agent': user_agent.random}  # Get a random user-agent\n",
    " \n",
    "    response = requests.get(url, headers=headers)  # Use the random user-agent in the request\n",
    "   \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for product in soup.find_all('div', class_= 'product-tuple-description'):\n",
    "        phone_name = product.find('p',class_='product-title')\n",
    "        MRP = product.find('span', class_='lfloat product-desc-price strike')\n",
    "        offer_price = product.find('span',class_ = 'lfloat product-price')\n",
    "\n",
    "        if phone_name and MRP and offer_price :\n",
    "            phone_name = phone_name.get_text()\n",
    "            MRP = MRP.get_text()\n",
    "            offer_price = offer_price.get_text()\n",
    "            Phones.append([phone_name,MRP,offer_price])\n",
    "\n",
    "\n",
    "base_url = 'https://www.snapdeal.com/search?keyword=phone&sort=rlvncy'\n",
    " \n",
    "num_pages = 25\n",
    "\n",
    "for page in range(1, num_pages + 1):\n",
    "    url = f'{base_url}&page={page}'\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    scrape_page(url)\n",
    "\n",
    "with open('LabbPhone.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['phone_name', 'MRP', 'offer_price'])\n",
    "    csv_writer.writerows(Phones)\n",
    " \n",
    "print(\"Data has been saved to 'LabbPhone.csv'\")\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
